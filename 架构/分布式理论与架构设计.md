# 分布式理论与架构设计学习笔记

# 一、分布式架构

分布式系统是一个硬件或软件分布在不同的计算机网络上，彼此间通过消息传递进行通信。通俗的讲，分布式系统是一个业务拆分成多个子业务，分布在不同的服务器节点，共同组成的一个系统。

## 1.1 分布式与集群

集群：多个服务器做一个事情

分布式：多个服务器做不同的事，如下图

![集群单体与分布式](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/%E9%9B%86%E7%BE%A4%E5%8D%95%E4%BD%93%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F.jpg)

## 1.2 分布式系统特性

1. 分布性

   空间中随机分布，这些计算机可以分布在不同机房、城市甚至国家

2. 对等性

   分布式系统中的计算机没有主从之分，所有节点都是对等的

3. 并发性

   同一个分布式系统的多个节点，可能会并发地操作一些共享的资源，诸如数据库或分布式存储。

4. 缺乏全局时钟

   既然各个计算机之间是依赖于交换信息来进行相互通信，很难定义两件事件的先后顺序，缺乏全局始终控制序列

5. 故障总会发生

   组成分布式的计算机，都有可能在某一时刻突然间崩掉。分的计算机越多，可能崩掉一个的几率就越大。如果再考虑到设计程序时的异常故障，也会加大故障的概率。

6. 处理单点故障

   单点SPoF（Single Point of Failure）：某个角色或者功能只有某一台计算机在支撑，在这台计算机上出现的故障是单点故障。

## 1.3 分布式系统面临的问题

1. 通信异常

   网络本身的不可靠属性，因此每次网络通信都会伴随着网络的不可用风险（光纤、路由、DNS等硬件设备或系统的不可用），都会导致分布式系统无法顺利进行一次网络通信，另外，即使分布式系统各节点之间的网络通信能正常执行，其延迟也会大于单机操作，存在巨大的延时差别，也会影响消息的收发过程，因此消息丢失和消息延迟变的非常普遍。

2. 网络分区

   网络之间出现了网络不联通，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成了若干个孤立的区域，分布式系统就会出现局部小集群，在极端情况下，这些小集群会独立完成原本需要整个分布式系统才能完成的功能，包括数据的事务处理，这就对分布式一致性提出非常大的挑战。

3. 节点故障

   这是分布式系统一个比较常见的问题，指的是组成分布式系统的服务器节点出现宕机或者僵死的现象

4. 三态

   分布式系统每一次请求与响应存在特有的三态概念，即成功失败和超时。

5. 重发

   分布式系统在发生调用的时候可能会出现超时，失败的情况，这时需要重新发起调用

6. 幂等

   一次或多次请求某一个资源对于资源本身应该具有同样的效果，也就是说，其任意多次执行对资源产生的结果均与一次执行的影响相同。

   ![幂等](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/%E5%B9%82%E7%AD%89.png)

# 二、分布式理论

## 2.1 数据一致性

分布式数据一致性，指的是数据在多份副本中存储时，各副本中的数据是一致的。

分布式系统当中，数据往往会有多个副本。多个副本就需要保证数据的一致性，这就带来了同步问题，因为网络延迟等因素，我们几乎没有办法保证同时更新所有机器当中的包括备份的所有数据，就会有数据不一致的情况。

![数据同步211030](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5211030.png)

总的来说，我们需要找到一种既能保证数据一致性又不影响系统运行的性能解决方案，所以一致性级别就由此诞生。

**一致性分类**

1. 强一致性

   这种一致性级别符合用户直觉，要求系统写入什么，读出来的就是什么，用户体验好，但对系统的性能影响最大，很难实现。

2. 弱一致性

   这种一致性级别约束了系统再写入成功后，不承诺立即读到写入的数据，也不承诺多久之后数据能达到一致，但会尽可能保证到某个时间级别后，数据能够达到抑制状态。

3. 最终一致性

   这也是弱一致性的一种，他无法保证数据更新后，所有的后续访问都能看到最新数值，而是需要一个时间，在这个事件之后可以保证一致，而在这个事件内数据也许是不一致的，这个系统无法保证强一致性的时间片段就被称为不一致窗口，不一致窗口的时间长短取决于很多因素，比如备份数据大小，网络速度，系统负载等。

最终一致性在实际应用中有如下变种：

1. 因果一致性

   如果进程A通知进程B它已更新了一个数据项，那么B的后续访问将返回更新后的值，与A无因果关系的进程C访问遵守一般的最终一致性规则。

   ![因果一致性](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/%E5%9B%A0%E6%9E%9C%E4%B8%80%E8%87%B4%E6%80%A7.png)

2. 读己之所写一致性

   当进程A自己更新一个数据项后，他总是访问更新过的值，不会看到旧值，这是因果一致性的特例。

   ![读己之所以一致性](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/%E8%AF%BB%E5%B7%B1%E4%B9%8B%E6%89%80%E4%BB%A5%E4%B8%80%E8%87%B4%E6%80%A7.png)

3. 会话一致性

   把访问存储系统的进程放到会话的上下文中，只要会话还在，系统就能保证读己之所写一致性如果由于某些失败情形令会话终止，就要建立新的会话，而且系统的保证不会延续到新的会话。

   ![会话一致性](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/%E4%BC%9A%E8%AF%9D%E4%B8%80%E8%87%B4%E6%80%A7.png)

4. 单调读一致性

   如果一个进程已经读取到一个特定值，那么该进程不会读取到该值以前的任何值。

   ![单调读一致性](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/%E5%8D%95%E8%B0%83%E8%AF%BB%E4%B8%80%E8%87%B4%E6%80%A7.png)

5. 单调写一致性

   系统保证对同一个进程的写操作串行化。

   ![单调写一致性](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/%E5%8D%95%E8%B0%83%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7.png)

**一致性模型**

![image-20211030121241212](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/image-20211030121241212.png)

## 2.2 CAP定理

CAP又称布鲁尔定理，指对一个分布式计算系统来说，不能能同时满足三点

**一致性**：所有节点访问的都是都是同一份最新的数据

这里指强一致性，也就是说在一致性系统中，一旦客户端将值写入任何一台服务器并获得响应，那么之后client从其他任何服务器读取的都是刚写入的数据。一致性保证了不管向哪台服务器（比如这边向S1）写入数据，其他的服务器（S2）能实时同步数据。

**可用性**：每次请求都能获取到非错的响应，但是不保证获取的数据为最新数据

系统中非故障节点收到的每个请求都必须有响应. 在可用系统中，如果我们的客户端向服务器发送请求，并且服务器未崩溃，则服务器必须最终响应客户端，不允许服务器忽略客户的请求

**分区容错性**：分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障

允许网络丢失从一个节点发送到另一个节点的任意多条消息，即不同步. 也就是说，G1和G2发送给对方的任何消息都是可以放弃的，也就是说G1和G2可能因为各种意外情况，导致无法成功进行同步，**分布式系统要能容忍这种情况**

![分区容错](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/%E5%88%86%E5%8C%BA%E5%AE%B9%E9%94%99.png)

### 2.2.1 CAP不可同时满足

如果假设有三者同时存在的系统，由于分区容错性，且因为通信不良Server1和Server2没有同步。这时将数据写入Server1，但Server1和Server2之间不同步，导致不满足一致性。

其余情况也类似，也就是说三至不能同时出现。

![CAP20211030](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/CAP20211030.png)

### 2.2.2 CAP三者权衡

**CA**

关注一致性和可用性，需要非常严格的全体一致协议，CA不能容忍网络错误或节点错误，一旦出现这样的问题整个系统就会拒绝请求，因为并不知道对面的节点是挂掉了还是网络问题，唯一安全的办法是把自己变成只读

**CP**

关注一致性和分区容忍性，它关注的是系统里大多数人的一致性协议。这样的系统只需要保证大多数结点数据一致，而少数的结点会在没有同步到最新版本的数据时变成不可用的状态。这样能够提供一部分的可用性。

**AP**

这样的系统关心可用性和分区容忍性。因此，这样的系统不能达成一致性，需要给出数据冲突，给出数据冲突就需要维护数据版本。

> 为了高可用，每个节点只能用本地数据提供服务，而这样会容易导致全局数据不一致性。对于互联网应用来说，机器数量庞大，节点分散，网络故障再正常不过了，那么此时就是保障AP，放弃C的场景，而从实际中理解，像网站这种偶尔没有一致性是能接受的，但不能访问问题就非常大了
>
> 对于银行来说，就是必须保证强一致性，也就是说C必须存在，那么就只用CA和CP两种情况，当保障强一致性和可用性（CA），那么一旦出现通信故障，系统将完全不可用。另一方面，如果保障了强一致性和分区容错（CP），那么就具备了部分可用性

## 2.3 BASE理论

上CAP 不可能同时满足，而分区容错性是对于分布式系统而言，是必须的。如果系统能够同时实现 CAP 是再好不过的了，所以出现了 BASE 理论。

BASE：全称：Basically Available(基本可用)，Soft state（软状态）,和 Eventually consistent（最终一致性）三个短语的缩写 ,Base 理论是对 CAP 中一致性和可用性权衡的结果，其来源于对大型互联网分布式实践的总结，是基于 CAP 定理逐步演化而来的。其核心思想是： 既是无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 

- 基本可用

  假设系统，出现了不可预知的故障，但相比较正常的系统而言还是能用。比如响应时间上的损失：正常情况下的搜索引擎 0.5 秒即返回给用户结果，而**基本可用**的搜索引擎可以在 1 秒返回结果。或者是功能上的损失：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单，但是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。

- 软状态

  什么是软状态呢？相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种 “硬状态”。软状态指的是：允许系统中的数据存在中间状态，并认为该状态不会影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。

- 最终一致性

  有个时间期限，在期限过后，应当保证所有副本保持数据一致性。从而达到数据的最终一致性。这个时间期限取决于网络延时，系统负载，数据复制方案设计等等因素

# 三、分布式一致性协议

## 3.1 两阶段提交协议(2PC)

两阶段提交协议简称2PC，是比较常用的解决分布式事务问题的方式，要么所有参与进程都提交事务，要么都取消事务，即实现ACID中的原子性的常用手段。

> 分布式事务: 事务提供一种操作本地数据库的不可分割的一系列操作 “要么什么都不做，要么做全套（All or Nothing）”的机制,而分布式事务就是为了操作不同数据库的不可分割的一系列操作 “要么什么都不做，要么做全套（All or Nothing）”的机制

![2PC20211101](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/2PC20211101.png)

### 3.1.1 2PC执行流程

**成功执行事务的流程：**

![2PC成功20211101](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/2PC%E6%88%90%E5%8A%9F20211101.png)

阶段一:

1.事务询问：协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应。

2.执行事务 (写本地的Undo/Redo日志)

3.各参与者向协调者反馈事务询问的响应

阶段二:

1.发送提交请求：协调者向所有参与者发出 commit 请求。

2.事务提交：参与者收到 commit 请求后，会正式执行事务提交操作，并在完成提交之后释放整个事务执行期间占用的事务资源。

3.反馈事务提交结果：参与者在完成事务提交之后，向协调者发送 Ack 信息。

4.完成事务：协调者接收到所有参与者反馈的 Ack 信息后，完成事务

**中断事务流程：**

![2PC失败20211101](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/2PC%E5%A4%B1%E8%B4%A520211101.png)

阶段一:

1.事务询问：协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应。

2.执行事务 (写本地的Undo/Redo日志)

3.各参与者向协调者反馈事务询问的响应

阶段二:

1.发送回滚请求：协调者向所有参与者发出 Rollback 请求。

2.事务回滚：参与者接收到 Rollback 请求后，会利用其在阶段一中记录的 Undo 信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源。

3.反馈事务回滚结果：

参与者在完成事务回滚之后，向协调者发送 Ack 信息。

4.中断事务：

协调者接收到所有参与者反馈的 Ack 信息后，完成事务中断。

### 3.1.2 2PC优缺点

**优点**：原理简单

**缺点**：

1. 同步阻塞

   在二阶段提交的执行过程中，所有参与该事务的逻辑都处于阻塞状态，即当参与者占有公共资源时，其他节点访问公共资源会处于阻塞状态

2. 单点问题

   若协调器出现问题，那么整个二阶段提交流程将无法运转，若协调者是在阶段二中出现问题时，那么其他参与者将会一直处于锁定事务资源的状态中，而无法继续完成事务操作

3. 数据不一致

   在阶段二，执行事务提交的时候，当协调者向所有的参与者发送commit请求之后，发生了局部网络异常或者是协调者在尚未发送完commit请求之前自身发生了崩溃，导致最终只有部分参与者收到了commit请求，于是会出现数据不一致的现象。

4. 太过保守

   在进行事务提交询问的过程中，参与者出现故障而导致协调者始终无法获取到所有参与者的响应信息的话，此时协调者只能依靠自身的超时机制来判断是否需要中断事务，这样的策略过于保守，即没有完善的容错机制，**任意一个结点的失败都会导致整个事务的失败**。

## 3.2 三阶段提交协议

一致性协议中设计出了二阶段提交协议（2PC），但是2PC设计中还存在缺陷，于是就有了三阶段提交协议。

3PC，全称three phase commit，是2PC的改进版，将2PC的提交十五请求过程一分为二，共形成了由CanCommit，PreCommit和doCommit三个阶段组成的事务处理协议。

![3PC20211101](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/3PC20211101.png)

三阶段提交基于二阶段的升级点：

- 3PC协议引入了超时机制
- 在第一阶段和第二阶段当中，引入了一个准备阶段，保证了在最后提交阶段之前个参数节点的状态是一致的

就是除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段

### 3.2.1 三阶段详解

1. 第一阶段

   类似2PC的准备阶段，协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。

   **事务询问**：协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。

   **响应反馈**：参与者接到CanCommit请求之后，正常情况下， 如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。 否则 反馈No

2. 第二阶段

   协调者根据参与者的反应情况来决定是否可以执行事务的PreCommit操作。根据响应情况，有以下两种可能：

   **Yes：**

    (1).发送预提交请求： 协调者向参与者发送PreCommit请求，并进入Prepared阶段。

    (2).事务预提交: 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。

    (3).响应反馈: 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终值令。

   **No：**

   假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。则有：

   (1).发送中断请求： 协调者向所有参与者发送abort请求。

   (2).中断事务: 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请

   求）,执行事务的中断

3. 第三阶段

   该阶段进行真正的事务提交，也可以分为执行提交和中断事务两种情况。

   **执行成功**

    (1).发送提交请求: 协调者接收到参与者发送的ACK响应，那么它将从预提交状态进入到提交状态。 并向所有参与者发送doCommit请求。

    (2).事务提交: 参与者接收到doCommit请求之后，执行正式的事务提交。 并在完成事务提交之后释放所有事务资源。

    (3).响应反馈: 事务提交完之后，向协调者发送ACK响应。

    (4).完成事务: 协调者接收到所有参与者的ACK响应之后，完成事务。

   中断事务

    (1).发送中断请求: 协调者向所有参与者发送abort请求

    (2).事务回滚: 参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作， 并在完成回滚之后释放所有的事务资源。

    (3).反馈结果: 参与者完成事务回滚之后，向协调者发送ACK消息

    (4).中断事务: 协调者接收到所有参与者反馈的ACK消息之后，执行事务的中断

如果在第三阶段协调者出现了问题或者协调者和参与者之间出现网络故障，最终都会导致参与者无法收到 doCommit 请求或者 abort 请求，针对这种情况，参与者都会在等待超时之后，继续进行事务提交

### 3.2.2 对比2PC

1.  首先对于协调者和参与者都设置了超时机制（在2PC中，只有协调者拥有超时机制，即如果在一定时间内没有收到参与者的消息则默认失败）,主要是避免了参与者在长时间无法与协调者节点通讯（协调者挂掉了）的情况下，无法释放资源的问题，因为参与者自身拥有超时机制会在超时后，自动进行本地commit从而进行释放资源。而这种机制也侧面降低了整个事务的阻塞时间和范围。
2. 通过**CanCommit**、**PreCommit**、**DoCommit**三个阶段的设计，相较于2PC而言，多设置了一个**缓冲阶段**保证了在最后提交阶段之前各参与节点的状态是一致的 。
3. PreCommit是一个缓冲，保证了在最后提交阶段之前各参与节点的状态是一致的。

> 3.3 NWR协议
>
> 3.4 Gossip协议
>
> 3.5 Paxos协议
>
> 3.6 Raft协议
>
> 3.7 Lease机制

# 四、分布式系统设计策略

分布式环境下，有几个问题是普遍关心的：保证节点存活，保证高可用，容错处理，负载均衡。

## 4.1 心跳检测

在分布式环境中，我们提及过存在非常多的节点（Node）。那么就有一个非常重要的问题，如何检测一个节点出现了故障乃至无法工作了？通常解决这一问题是采用心跳检测的手段。

心跳顾名思义，就是以**固定的频率**向其他节点汇报当前节点状态的方式。收到心跳，一般可以认为一个节点和现在的网络是良好的。当然，心跳汇报时，一般也会携带一些附加的状态、元数据信息，以便管理。

如下图：

![心跳演示20211101](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/%E5%BF%83%E8%B7%B3%E6%BC%94%E7%A4%BA20211101.png)

如果Server没有收到节点3的心跳，则认为失恋，但失联并不意味着节点3故障也可能是繁忙或链路故障，所以可以通过一些方法帮助Server做决定是否某一节点已经死亡：周期检测心跳机制、累计失效检测。

- 周期检测心跳机制

  Server端每间隔 t 秒向Node集群发起监测请求，设定超时时间，如果超过超时时间，则判断“死 亡”。可以把该节点踢出集群

- 累计失效检测机制

  在周期检测心跳机制的基础上，统计一定周期内节点的返回情况（包括超时及正确返回），以此计算节点的“死亡”概率。另外，对于宣告“濒临死亡”的节点可以发起有限次数的重试，以作进一步判断。如果超过次数则可以把该节点踢出集群

## 4.2 高可用

高可用(High Availability)是系统架构设计中必须考虑的因素之一,通常是指,经过设计来减少系统不能提供服务的时间 .比如：

| 可用性  | 一年中可故障时长 | 一天可故障时长 |
| ------- | ---------------- | -------------- |
| 90%     | 36.5天           | 144分钟        |
| 99%     | 3.6天            | 14.4分钟       |
| 99.999% | 5.3分钟          | 860ms          |

系统高可用性的常用设计模式包括三种：主备（Master-SLave）、互备（Active-Active）和集群（Cluster）模式。

1. 主备模式

   主备模式就是Active-Standby模式，当主机宕机时，备机接管主机的一切工作，待主机恢复正常后，按使用者的设定以自动（热备）或手动（冷备）方式将服务切换到主机上运行。在数据库部分，习惯称之为MS模式。MS模式即Master/Slave模式，这在数据库高可用性方案中比较常用，如MySQL、Redis等就采用MS模式实现主从复制，保证高可用。

2. 互备模式

   互备模式指两台主机同时运行各自的服务工作且相互监测情况。在数据库高可用部分，常见的互备是MM模式。MM模式即Multi-Master模式，指一个系统存在多个master，每个master都具有read-write能力，会根据时间戳或业务逻辑合并版本。

3. 集群

   集群模式是指有多个节点在运行，同时可以通过主控节点分担服务请求。集群模式需要解决主控节点本身的高可用问题，一般采用主备模式。

### 4.2.1高可用下的脑裂问题

在高可用（HA）系统中，当联系两个节点的"心跳线"断开时(即两个节点断开联系时)，本来为一个整体、动作协调的HA系统，就分裂成为两个独立的节点(即两个独立的个体)。由于相互失去了联系，都以为是对方出了故障，两个节点上的HA软件像"裂脑人"一样，"本能"地争抢"共享资源"、争起"应用服务"，就会发生严重后果：

- 共享资源被瓜分，两边服务都无法启动
- 两边服务都启动，但同时读写共享存储，导致数据损坏（如数据库轮询着的联机日志出错）

两个节点相互争抢共享资源，结果会导致系统混乱，数据损坏。对于无状态服务的HA，无所谓脑裂不脑裂，但对有状态服务(比如MySQL)的HA，必须要严格防止脑裂。

一般来说，裂脑的发生，有以下几种**原因**：

1. 高可用服务器各节点之间心跳线链路发生故障，导致无法正常通信。
2. 因网卡及相关驱动坏了，ip配置及冲突问题（网卡直连）。
3. 因心跳线间连接的设备故障（网卡及交换机）。
4. 因仲裁的机器出问题（采用仲裁的方案）。
5. 高可用服务器上开启了iptables防火墙阻挡了心跳消息传输。
6. 高可用服务器上心跳网卡地址等信息配置不正确，导致发送心跳失败。
7. 其他服务配置不当等原因，如心跳方式不同，心跳广插冲突、软件Bug等。

**预防方案：**

- 添加冗余的心跳线 [即冗余通信的方法]

  同时用两条心跳线路 (即心跳线也HA)，这样一条线路坏了，另一个还是好的，依然能传送心跳消息，尽量减少"脑裂"现象的发生几率。

- 仲裁机制

当两个节点出现分歧时，由第3方的仲裁者决定听谁的。这个仲裁者，可能是一个锁服务，一个共享盘或者其它什么东西

- Lease机制

- 隔离(Fencing)机制
  - 共享存储fencing：确保只有一个Master往共享存储中写数据。
  - 客户端fencing：确保只有一个Master可以响应客户端的请求。
  - Slave fencing：确保只有一个Master可以向Slave下发命令

## 4.3 容错性

容错顾名思义就是IT系统对于错误包容的能力。容错的处理是保障分布式环境下相应系统的高可用或者健壮性，一个典型的案例就是对于缓存穿透问题。

如何解决缓存穿透：布隆过滤器。

## 4.4 负载均衡

负载均衡：其关键在于使用多台集群服务器共同分担计算任务，把网络请求及计算分配到集群可用的不同服务器节点上，从而达到高可用性及较好的用户操作体验。

以Nginx为例，有六种策略

| 方案             | 说明                                                         |
| ---------------- | ------------------------------------------------------------ |
| 轮询             | 默认方式,每个请求会按时间顺序逐一分配到不同的后端服务器      |
| weight           | 权重方式,在轮询策略的基础上指定轮询的几率,权重越大,接受请求越多 |
| ip_hash          | 依据ip分配方式,相同的客户端的请求一直发送到相同的服务器，以保证session会话 |
| least_conn       | 最少连接方式,把请求转发给连接数较少的后端服务器              |
| fair(第三方)     | 响应时间方式,按照服务器端的响应时间来分配请求，响应时间短的优先分配 |
| url_hash(第三方) | 依据URL分配方式,按访问url的hash结果来分配请求，使每个url定向到同一后端服务器 |

# 五、分布式架构服务调用



