# 分布式系统的抽象与实现技术

**By Loserfromlazy**



> 本文是MIT的分布式系统课程6.824的学习笔记包括课程的lab的实现。学习的目的主要是扎实基础，能更加深刻的理解分布式系统。
>
> **未经授权请勿转载本笔记。创作不易，请尊重作者，违者必究！！！**
>
> 关于学习过程中的参考资料请见本文的参考资料章节，该章节放在了最后。

# 一、概述

## 1.1 概述

什么是分布式系统？实际上分布式系统是协调提供服务的一组计算机就是分布式系统。为什么我们需要分布式系统呢？主要有四方面原因：

- 可以通过并行计算获得更高的性能

- 可以通过复制来提供容错

  比如两台计算机做主从复制

- 匹配物理设备的分布

  比如在纽约有一台服务器A、伦敦有一台服务器B，我们需要协调这种物理位置的分布。

- 通过隔离来提高安全性

  比如有一些代码并不被信任，但是又需要和它进行交互。所以可以将代码分散在多处运行，这样不同的代码在不同的计算机运行，通过特定的网络协议通信，这样可以限制出错。

实现分布式系统并不容易，主要有以下几个问题或挑战：

- concurrency，并发
- complex interactions，复杂交互
- partial failure，局部错误
- hard to get high performance，很难获得高性能

因为分布式系统有很多部分，所以会遇到并发以及复杂交互带来的问题（比如同步、异步等）。同时由多台计算机组成的分布式系统，可能会有一部分组件在工作，而另一部分组件停止运行，所以局部错误也是其中一大难点。最后一个难点就是分布式系统很难获得高性能，因为设计分布式系统的根本原因通常是为了获得更高的性能，比如说一千台计算机能达到的性能。但是实际上一千台机器到底有多少性能需要小心设计让系统达到预期。

由于分布式系统难点很多，所以我们应该学习如何解决这些难点。

> PS：在设计一个系统时或者面对一个需要解决的问题时，如果可以在一台计算机上解决，而不需要分布式系统，那就应该用一台计算机解决问题。有很多的工作都可以在一台计算机上完成，并且通常比分布式系统简单很多。所以，在选择使用分布式系统解决问题前，你应该要充分尝试别的思路，因为分布式系统会让问题解决变得复杂。

## 1.2 分布式系统的抽象与实现

分布式系统的问题可以抽象成三大类，分别是：

- 存储
- 通信
- 计算

我们抽象的目的是为了隐藏分布式系统的复杂性。比如我们可以提供一些抽象的接口，将分布式系统的特性隐藏在整个系统内，从应用程序的角度来看，整个系统是一个非分布式的系统。我们的最终目的就是希望构建一个接口，它看起来就像一个非分布式存储和计算系统一样，但是实际上又是一个有极高的性能和容错性的分布式系统。

那么我们该如何实现呢？在构建分布式系统中，人们是用了很多工具：

- RPC
- Thread
- concurrency control（并发控制）
- ...

这些都是实现分布式系统的编程工具，也是用来构建分布式系统的工具。

在构建分布式系统的过程中我们还需要几个问题：

- 性能
- 可扩展性
- 容错
- 一致性

下面我们一一来看：

### 1.2.1 分布式系统的可用性

**说起可用性，最重要的话题就是容错。**如果只使用一台计算机构建系统，那么系统大概率是可靠的。因为一台计算机通常可以用很多年。然而如果用数千台计算机构建系统，那么即使每台计算机可以稳定运行一年，对于1000台计算机也意味着平均每天会有3台计算机故障。

所以对于大型分布式系统有一个很大的问题就是，总是会有故障，要么是机器故障，要么是运行出错，要么是运行缓慢，要么是执行错误的任务。其中最常见的问题就是网络问题，在一个有1000台计算机的网络中，会有大量的网络电缆和网络交换机，所以有可能会有很多问题产生，比如网线从接口掉出，或者交换机风扇故障导致交换机过热而不工作。

因此大型分布式系统总是会有各种各样的问题出现，所以设计分布式系统时就需要考虑错误的发生，或者说能够在出错时继续运行。**关于容错的设计，有一个共同的思想，就是可用性（Availability）。**某些系统经过精心的设计，这样在特定的错误类型下，系统仍然能够正常运行，仍然可以像没有出现错误一样提供完整的服务。比如可以构建一个有多副本系统，其中一个故障了另一个可以继续允许，但是如果两个副本都故障了，那么系统就不再有可用性。**所以，可用系统通常是指，在特定的故障范围内，系统仍然能够提供服务，系统仍然是可用的。如果出现了更多的故障，系统将不再可用。**

除了可用性之外，**另一种容错特性是自我可恢复性（recoverability）**。即如果出现了问题服务会停止工作，不再响应请求，之后有人来修复，并且在修复之后系统仍然可以正常运行，就像没有出现过问题一样。对于一个可恢复的系统通常需要做一些操作，例如将最新的数据存放在磁盘中，这样在供电恢复之后（假设故障就是断电），才能将这些数据取回来。甚至说对于一个具备可用性的系统，为了让系统在实际中具备应用意义，也需要具备可恢复性。

如果想实现上面的特性，有很多种实现的方式，其中最重要的方式有两个：

- 一是非易失存储（non-volatile storage，类似于硬盘）。这样当出现类似电源故障，甚至整个机房的电源都故障时，我们可以使用非易失存储，比如硬盘，闪存，SSD之类的，这样当备用电源恢复或者某人修好了电力供给，还是可以从硬盘中读出系统最新的状态，并从那个状态继续运行。
- 二是复制（replication），即实现一个多副本系统。但是要注意，多副本系统存在一致性问题，比如有两台服务器，它们本来应该是有着相同的系统状态，但是这两个副本总是会意外的偏离同步的状态，而不再互为副本。对于任何一种使用复制实现容错的系统，都会面临这个问题。

### 1.2.2 分布式系统的一致性

下面有一个例子来理解一致性：比如我们想构建一个分布式存储系统，假设这是一个KV服务。这个KV服务只支持两种操作，一个get、一个put。一致性是分布式系统中重要的问题，是因为，从性能和容错的角度来说，我们通常会有多个副本。在一个分布式系统中，由于复制或者缓存，数据可能存在于多个副本当中，于是就有了多个不同版本的key-value对。

假设两个副本的key1的一开始的数值都是20。现在客户端1发送了一个put请求，并希望将key1改为21，假设这个请求发给了服务器1，如下图（图片是我自己的goodnotes笔记）：

![image-20230714100221895](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/image-20230714100221895.png)

之后会将请求发给第二个服务器，因为只有这样才能保持两个副本同步。但是这时客户端故障了（比如电源故障之类的）这时就会有问题了，因为两个副本的值不一样了。如果这时有另一个客户端发送了get操作读取key为1的值，这时即可能获得21，也可能获得20，取决于get请求发送到了哪个服务器。这时两个副本的值并不能保持一致，所以这时如果想保持副本的一致性需要确定put/get操作的一些规则。

实际上，对于一致性有很多不同的定义。一般分为强一致性和弱一致性，弱一致是指，不保证get请求可以得到最近一次完成的put请求写入的值。强一致可以保证get得到的是put写入的最新的数据；而很多的弱一致系统不会做出类似的保证。

弱一致存在的原因是，虽然强一致可以确保get获取的是最新的数据，但是实现这一点的代价非常高。几乎可以确定的是，分布式系统的各个组件需要做大量的通信，才能实现强一致性。如果你有多个副本，那么不管get还是put都需要询问每一个副本。比如在上面的例子中，如果想实现强一致性简单的方法就是同时读两个副本，如果有多个副本就读取所有的副本，并使用最近一次写入的数据。但是这样的代价很高，因为需要大量的通信才能得到一个数据。

当使用多副本来完成容错时，需要每个副本都有独立的出错概率，这样故障才不会关联。比如如果两个副本在同一个机房，那么这时如果断电则两个副本都没了，就不能保证容错性了。所以，为了使副本的错误域尽可能独立，为了获得良好的容错特性，人们希望将不同的副本放置在尽可能远的位置，例如在不同的城市或者在大陆的两端。这时如果还要保证强一致的通信，代价可能会非常高。因为每次执行put或者get请求，都需要等待几十毫秒来与数据的两个副本通信。

所以，人们常常会使用弱一致系统，只需要更新最近的数据副本，并且只需要从最近的副本获取数据。在学术界和工业界，有大量关于构建弱一致性保证的研究。所以，弱一致对于应用程序来说很有用，并且它可以用来获取高的性能。

### 1.2.3 分布式系统的性能和可扩展性

分布式系统还有一个重要的特性，那就是性能。通常来说，构建分布式系统的目的是为了获取到可扩展的加速。所以，我们这里追求的是可扩展性（Scalability）。

> 这里可扩展或者可扩展性指的是，如果我用一台计算机解决了一些问题，当加入第二台计算机，只需要一半的时间就可以解决这些问题。

可扩展性是一个很强大的特性，因为构建了一个系统只需要增加计算机的数量，系统就能提高相对应的性能或吞吐量。但是如果不增加计算机，就需要重构系统，进而使这些系统有更高的性能，更高的运行效率，或者应用一个更好的算法之类的。通常这样更昂贵，因为对比与人工费用，机器的费用更便宜。所以，当使用一整个机房的计算机来构建大型网站的时候，为了获取对应的性能，必须要时刻考虑可扩展性。

假设我们现在有一个网站，当只有1-2个用户时，一台计算机就可以运行web服务器和数据，或者一台计算机运行web服务器，一台计算机运行数据库。但是假设网站一夜之间就火了起来，就可能有一亿人要登录你的网站，这里可以花费大量时间极致优化你的网站，但是很显然没有那个时间。所以，为了提升性能，第一件事情就是购买更多的web服务器，然后把不同用户分到不同服务器上。这样，一部分用户可以去访问第一台web服务器，另一部分去访问第二台web服务器。

注意这种可扩展性并不是无限的。很可能在某个时间点有了10台，20台，甚至100台web服务器，它们都在和同一个数据库通信。现在，数据库成为了新的瓶颈。这时必然要做一些重构工作。可能需要将一个数据库拆分成多个数据库，进而提升性能，但是这需要大量的工作。单个数据库或者存储服务器不能支撑这样规模的网站，所以才需要分布式存储。

## 1.3 MapReduce介绍

> [MapReduce论文地址](https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf)

### 1.3.1 MapReduce背景

MapReduce是由Google设计，开发和使用的一个系统，相关的论文在2004年发表。Google当时面临的问题是，他们需要在TB级别的数据上进行大量的计算。如果用一台计算机对这样的数据进行排序，需要的时间是不可接受的，因为输入的数据很大，所以需要将计算分布在成百上千的计算机上，并在合理的时间完成。

要实现这种形式，工程师们需要将手头的问题分包到大量计算机上去完成，管理这些运算，并将数据取回。这样是很麻烦的，且需要一定的技术水平，所以谷歌重新设计了一种抽象，将细节进行隐藏（比如如何将运算工作分发到数千台计算机，如何组织这些计算机，如何移动数据，如何处理故障等等这些细节），这种抽象可以让普通程序员也可以轻松使用分布式计算。这就是MapReduce的背景。

MapReduce的思想是，应用程序设计人员和分布式运算的使用者，只需要写简单的Map函数和Reduce函数，而不需要知道任何有关分布式的事情，MapReduce框架会处理剩下的事情。

### 1.3.2 MapReduce编程模型

MapReduce的整体流程如下图（图片来自mapreduce的论文）：

![image-20230714104710151](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/image-20230714104710151.png)

如上图，首先MapReduce会有一些输入，这些输入被分割成大量的不同的文件或者数据块。MapReduce的库会将输入的文件分成M块，通常每块16M-64M。然后会在机器集群上启动MapReduce的很多副本。

MapReduce的这些副本中，其中一个是Master节点，其他的都是Worker节点。假设一共有M个map任务和R个reduce任务。（map任务主要是处理刚刚被拆分的输入的文件，reduce任务主要是处理map任务输出的中间值）Master节点会选择空闲的Worker节点分配任务。

被分为M块的输入文件先执行map函数进行处理。被分配map任务的worker节点，会将将输入文件进行处理，首先会解析输入数据耳带键值对，然后传给用户自定义的map函数。map函数的输出是一个键值对的列表，map函数的输出被叫做中间键值对。map函数的输出会被缓存在内存中。

然后这些缓存会被定期写入磁盘，通过分区函数划分为R区域。这些缓存在本地磁盘的位置会被传回Master节点，Master负责将这些传给负责reduce任务的Worker。

当worker被分配reduce任务时，worker使用远程调用从负责map任务的worker的本地磁盘中读取所有的中间键值对，然后会将键值对排序以便将相同的键分组到一起。如果中间键值对太大，内存不够的话就会使用外部排序。

然后负责reduce任务的worker会遍历刚刚排序分组的数据，对于每一个唯一的中间键，将该键和中间值集合传给用户的reduce函数。reduce函数的输出最终会被保存在最终的输出文件中。

最后当所有的map任务和reduce任务都完成后，主线程将唤醒用户线程，用户的MapReduce调用将返回。

> 上面的MapReduce流程是以论文为主总结的。
>
> MIT6.824课堂上以单词计数为例，讲解了MapReduce的运行，这里不再赘述。在lab1中会用go实现单词计数的MapReduce实现。

# 二、go语言的RPC与线程

> 已完成，待整理

> 关于go语言的学习可以参考我的学习笔记[Go语言学习笔记](https://github.com/Loserfromlazy/Code_Career/blob/master/%E9%9D%9EJava%E6%8A%80%E6%9C%AF%E6%A0%88/Go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.md),我学习go的相关参考资料也在该笔记中。
>
> 本小节主要跟随6.824课程简单整理下Go语言的优点，以及Go语言的RPC与线程

## 2.1 为什么选择Go

关于这节课的lab使用go语言而非其他语言比如Java的原因主要有以下几点：

- Go对线程支持良好
- 使用RPC非常方便
- 有类型和内存安全
- Go有垃圾收集机制
- Go编写程序不是特别复杂
- 最近很多分布式系统都是用Go编写的

## 2.2 Threads

线程是实现并发的重要工具，在Go语言中，只需要在方法前加上go关键字即可实现并发。

为什么使用线程？

1. 首先线程可以提高IO并行，也就是提高吞吐量。客户端同时向多个服务器发送请求并等待应答，服务器处理多个客户端请求。
2. 其次使用线程可以更好地发挥多核CPU的性能，线程可以方便的再多个核心上并行执行代码。
3. 最后是便利性。

那么是否有线程的替代品？

有，即事件驱动编程模式。这种方式会保存每个请求的状态表，然后在单线程中有一个事件循环（即死循环），在循环中进行请求的处理分发。Reactor模式就是一种事件驱动的方式，在Java的NIO和Netty中都使用了这种方式提高性能。

但是单线程的事件驱动虽然消除了线程成本，但并没有利用到多核CPU的优势，且实现比较困难。

> 一般来说事件驱动都与多线程结合使用，以提高性能。

使用多线程编程有以下几个困难或者说是挑战：

1. 首先需要保证共享数据的安全

   这个问题简单来说就是两个线程同时执行`n = n + 1`如何保证n的数据正确顶？

   一般来说有以下几种方式：

   - 使用锁

     > 在Go语言中，可以使用锁，在sync包下，常用的有Mutex互斥锁和RWMutex读写锁。
     >
     > 互斥锁的用法如下：
     >
     > ```go
     > var lock sync.Mutex //互斥锁
     > lock.Lock() //加锁
     > //doSomething
     > lock.Unlock() //解锁
     > ```

   - 避免可变数据的共享

2. 其实是实现线程间的协调

   一个线程产生数据，另一个线程消费数据，消费者如何等待，生产者如何唤醒消费者？这就是典型的生产者消费者问题。

   在编程语言中一般都有对应的线程同步机制。

   > 在GO语言中通过channel进行线程间通信,在GO中不是通过共享内存来通信，而应通过通信来共享内存。
   >
   > 除了channel还可以使用sync.Cond或sync.WaitGroup来进行线程同步。

3. 最后是解决死锁问题

## 2.3 GO语言使用线程的例子

在MIT6.824的课堂上，通过网络爬虫来展示了Go语言使用线程的示例，分别用了单线程，使用了锁的多线程，使用了channel的多线程来实现网络爬虫：

```go
package main

import (
	"fmt"
	"sync"
)

//
// Several solutions to the crawler exercise from the Go tutorial
// https://tour.golang.org/concurrency/10
//

//
// Serial crawler
//

func Serial(url string, fetcher Fetcher, fetched map[string]bool) {
	if fetched[url] {
		return
	}
	fetched[url] = true
	urls, err := fetcher.Fetch(url)
	if err != nil {
		return
	}
	for _, u := range urls {
		Serial(u, fetcher, fetched)
	}
	return
}

//
// Concurrent crawler with shared state and Mutex
//

type fetchState struct {
	mu      sync.Mutex
	fetched map[string]bool
}

func (fs *fetchState) testAndSet(url string) bool {
	fs.mu.Lock()
	defer fs.mu.Unlock()
	r := fs.fetched[url]
	fs.fetched[url] = true
	return r
}

func ConcurrentMutex(url string, fetcher Fetcher, fs *fetchState) {
	if fs.testAndSet(url) {
		return
	}
	urls, err := fetcher.Fetch(url)
	if err != nil {
		return
	}
	var done sync.WaitGroup
	for _, u := range urls {
		done.Add(1)
		go func(u string) {
			defer done.Done()
			ConcurrentMutex(u, fetcher, fs)
		}(u)
	}
	done.Wait()
	return
}

func makeState() *fetchState {
	return &fetchState{fetched: make(map[string]bool)}
}

//
// Concurrent crawler with channels
//

func worker(url string, ch chan []string, fetcher Fetcher) {
	urls, err := fetcher.Fetch(url)
	if err != nil {
		ch <- []string{}
	} else {
		ch <- urls
	}
}

func coordinator(ch chan []string, fetcher Fetcher) {
	n := 1
	fetched := make(map[string]bool)
	for urls := range ch {
		for _, u := range urls {
			if fetched[u] == false {
				fetched[u] = true
				n += 1
				go worker(u, ch, fetcher)
			}
		}
		n -= 1
		if n == 0 {
			break
		}
	}
}

func ConcurrentChannel(url string, fetcher Fetcher) {
	ch := make(chan []string)
	go func() {
		ch <- []string{url}
	}()
	coordinator(ch, fetcher)
}

//
// main
//

func main() {
	fmt.Printf("=== Serial===\n")
	Serial("http://golang.org/", fetcher, make(map[string]bool))

	fmt.Printf("=== ConcurrentMutex ===\n")
	ConcurrentMutex("http://golang.org/", fetcher, makeState())

	fmt.Printf("=== ConcurrentChannel ===\n")
	ConcurrentChannel("http://golang.org/", fetcher)
}

//
// Fetcher
//

type Fetcher interface {
	// Fetch returns a slice of URLs found on the page.
	Fetch(url string) (urls []string, err error)
}

// fakeFetcher is Fetcher that returns canned results.
type fakeFetcher map[string]*fakeResult

type fakeResult struct {
	body string
	urls []string
}

func (f fakeFetcher) Fetch(url string) ([]string, error) {
	if res, ok := f[url]; ok {
		fmt.Printf("found:   %s\n", url)
		return res.urls, nil
	}
	fmt.Printf("missing: %s\n", url)
	return nil, fmt.Errorf("not found: %s", url)
}

// fetcher is a populated fakeFetcher.
var fetcher = fakeFetcher{
	"http://golang.org/": &fakeResult{
		"The Go Programming Language",
		[]string{
			"http://golang.org/pkg/",
			"http://golang.org/cmd/",
		},
	},
	"http://golang.org/pkg/": &fakeResult{
		"Packages",
		[]string{
			"http://golang.org/",
			"http://golang.org/cmd/",
			"http://golang.org/pkg/fmt/",
			"http://golang.org/pkg/os/",
		},
	},
	"http://golang.org/pkg/fmt/": &fakeResult{
		"Package fmt",
		[]string{
			"http://golang.org/",
			"http://golang.org/pkg/",
		},
	},
	"http://golang.org/pkg/os/": &fakeResult{
		"Package os",
		[]string{
			"http://golang.org/",
			"http://golang.org/pkg/",
		},
	},
}
```

## 2.4 go语言使用RPC的例子

```go
package main

import (
	"fmt"
	"log"
	"net"
	"net/rpc"
	"sync"
)

//
// Common RPC request/reply definitions
//

type PutArgs struct {
	Key   string
	Value string
}

type PutReply struct {
}

type GetArgs struct {
	Key string
}

type GetReply struct {
	Value string
}

//
// Client
//

func connect() *rpc.Client {
	client, err := rpc.Dial("tcp", ":1234")
	if err != nil {
		log.Fatal("dialing:", err)
	}
	return client
}

func get(key string) string {
	client := connect()
	args := GetArgs{"subject"}
	reply := GetReply{}
	err := client.Call("KV.Get", &args, &reply)
	if err != nil {
		log.Fatal("error:", err)
	}
	client.Close()
	return reply.Value
}

func put(key string, val string) {
	client := connect()
	args := PutArgs{"subject", "6.824"}
	reply := PutReply{}
	err := client.Call("KV.Put", &args, &reply)
	if err != nil {
		log.Fatal("error:", err)
	}
	client.Close()
}

//
// Server
//

type KV struct {
	mu   sync.Mutex
	data map[string]string
}

func server() {
	kv := &KV{data: map[string]string{}}
	rpcs := rpc.NewServer()
	rpcs.Register(kv)
	l, e := net.Listen("tcp", ":1234")
	if e != nil {
		log.Fatal("listen error:", e)
	}
	go func() {
		for {
			conn, err := l.Accept()
			if err == nil {
				go rpcs.ServeConn(conn)
			} else {
				break
			}
		}
		l.Close()
	}()
}

func (kv *KV) Get(args *GetArgs, reply *GetReply) error {
	kv.mu.Lock()
	defer kv.mu.Unlock()

	reply.Value = kv.data[args.Key]

	return nil
}

func (kv *KV) Put(args *PutArgs, reply *PutReply) error {
	kv.mu.Lock()
	defer kv.mu.Unlock()

	kv.data[args.Key] = args.Value

	return nil
}

//
// main
//

func main() {
	server()

	put("subject", "6.5840")
	fmt.Printf("Put(subject, 6.5840) done\n")
	fmt.Printf("get(subject) -> %s\n", get("subject"))
}
```

# 三、LAB1——go语言实现MapReduce_Demo

> 已完成，待整理

> 在开始本实验之前最好先完成Go语言的学习，熟悉常用语法,关于go语言的学习可以参考我的学习笔记[Go语言学习笔记](https://github.com/Loserfromlazy/Code_Career/blob/master/%E9%9D%9EJava%E6%8A%80%E6%9C%AF%E6%A0%88/Go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.md),我学习go的相关参考资料也在该笔记中。
>
> **关于6.824的实验：实验内容一定要自己做，可以看别人的思路，但是内容一定要自己做，不然实验就会没有意义。包括本文中也只会展示我的思路，关于我的实验通过的代码这里也只给出仓库地址。**
>
> 作为第一个lab，我在一开始做的时候也很懵，刚开始也无从下手，而且作为一个Java开发人员，对go的编译器和开发也不是很熟练。所以为了帮助大家快速上手，第一个实验我将从实验环境的搭建、如何编写实验代码、代码如何测试、每一步如何操作并结合官网的要求和论文以及我自己的排坑和学习心得，详细的写一节入门指南，后续的实验就只会提供我个人的实验思路和代码仓库地址。



# 四、分布式存储——GFS

> 已完成，待整理

# 五、主备复制

> 正在学习

# 参考资料

- [MIT6.824](https://pdos.csail.mit.edu/6.824/schedule.html)这门课可以说是明星课程了，将主流的分布式系统软件讲的浅显易懂。这里给出的是2023年课程的Schedule页面。

- [MIT6.824中英双语字幕](https://www.bilibili.com/video/BV1R7411t71W/?spm_id_from=333.337.search-card.all.click)这个是B站的中英双语字幕的课程视频，课程是2020年的视频，2020年主讲老师是Robert Morris。（我个人很喜欢这个老师）作为写出蠕虫病毒的大神，Robert教授能够一种理论联系实际的方式，将主流的分布式系统软件讲的浅显易懂。推荐学习时尽量看英文字幕，毕竟是机翻，有些地方并不是很准确。

- [MIT6.824的课程翻译](https://github.com/huihongxiao/MIT6.824)非常感谢huihongxiao大神的翻译降低了学习的难度。

- [实验lab1的指导](https://blog.csdn.net/weixin_45938441/article/details/124018485)对于第一次写go和做MIT的实验的同学刚上手可能会懵，我刚开始做实验时就很懵，对go的生疏和对实验的不了解导致上手十分困难，这篇博客的环境搭建和入门指导写的还不错。

  > PS：实验内容一定要自己做，可以看别人的思路，但是内容一定要自己做，不然实验就会没有意义。包括本文中也只会展示我的思路，关于我的实验通过的代码这里也只给出仓库地址。

- 

