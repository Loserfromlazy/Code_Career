# 项目中遇到的问题及解决思路

## 一、解决过多if-else的问题

通常是使用策略模式或工厂模式来解决，但是弊端就是如果有很多if-else就需要创建很多的类，所以在项目中使用了Map加Function接口的方式来结局if-else的问题，代码如下：

```java
public class ServicelImpl {

    static FunctionImpl function = new FunctionImpl();
    //如果需要传两个参数即(sn1,sn2)->{}的形式，可以使用BiFunction
    static Map<Integer, Function<String,String>> map = new HashMap();

    private static void Init(){
        map.put(5,sn->function.func1((String) sn));
        map.put(6,sn->function.func1((String) sn));
        map.put(7,sn->function.func1((String) sn));
    }

    public static void pullTask(String sn){
        //根据sn查询任务
        int taskType =5 ;//数据库查询出来的任务类型
        Function<String,String> function = map.get(taskType);
        Object apply = function.apply(sn);
        System.out.println(apply);

    }

    public static void main(String[] args) {
        Init();
        pullTask("123");
    }

}
```

```java
public class FunctionImpl {

    public String func1(String str1){
        //do
        return str1;
    }
    public String func2(String str1){
        //do
        return str1;
    }
    public String func3(String str1){
        //do
        return str1;
    }
}
```

思路就是，将策略模式中的策略存入Function，在业务中使用时，只需要调用init()初始化这个Map或者使用`@PostConstruct`，然后就不需要额外每次多一种类型都需要在下面在加一个if-else。

> 被`@PostConstruct`修饰的方法会在加载servlet的时候运行，且只会被执行一次。类似于Servlet的`init()`方法。被`@PostConstruct`修饰的方法会在构造方法之后，`init()`方法之前运行。
>
> 类似的注解还有`@PreConstruct`，被`@PreConstruct`修饰的方法在服务器卸载Servlet的时候运行，并且只会被服务器调用一次，类似于Servlet的`destroy()`方法，被`@PreConstruct`修饰的方法会在`destroy()`方法之后运行，在Servlet被彻底卸载之前。

## 二、检查APK签名版本

在需要判断apk签名版本时可以使用如下方法：

可以在powershell中，进入到sdk的路径，如下：

` cd C:\Users\XXX\AppData\Local\Android\Sdk\build-tools\27.0.3`

然后在此文件夹中执行命令：

` .\apksigner verify -v xxx.apk`

即可检查apk签名的版本是V1还是V2

## 三、安卓端通过命令启动应用

安卓端可以通过`adb shell am start -n package/launch_activity`

其中上述的package是该app的包名，launch_actity是该app的主Activity（需要全限定类型，即包名+类名），可以通过打开该APP然后使用命令`adb shell dumpsys window|findstr current`来获取当前Activity的类名。

## 四、Spring手动回滚事务

应用场景是当我们需要对业务层进行try-catch时，上层无法获取我们的异常，所以@Transactional无法进行回滚，这时需要我们在catch中手动回滚或者在抛出异常。

```java
TransactionAspectSupport.currentTransactionStatus().setRollbackOnly();
```

## 五、排除数据库依赖

除了要排除`DataSourceAutoConfiguration`还应该排除`DruidDataSourceAutoConfigure`。因为有的依赖还是用了Druid数据库

```java
@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class, DruidDataSourceAutoConfigure.class,})
```

## 六、mysql instr函数

函数语法:

`INSTR（str,substr） / instr(源字符串, 目标字符串)`

参数说明：

str：从哪个字符串中搜索；

substr:要搜索的子字符串。

例如：INSTR('apple','a')，返回的查询结果是1，因为a出现在字符串‘apple’中的第一个索引；

业务场景：查询一个表中的字段是否包含另一个表中的字段

## 七、mysql REGEXP（mysql正则）

Whether string matches regular expression 字符串是否匹配正则，官方文档用法示例：

~~~mysql
mysql> SELECT 'Michael!' REGEXP '.*';
+------------------------+
| 'Michael!' REGEXP '.*' |
+------------------------+
|                      1 |
+------------------------+
mysql> SELECT 'new*\n*line' REGEXP 'new\\*.\\*line';
+---------------------------------------+
| 'new*\n*line' REGEXP 'new\\*.\\*line' |
+---------------------------------------+
|                                     0 |
+---------------------------------------+
mysql> SELECT 'a' REGEXP '^[a-d]';
+---------------------+
| 'a' REGEXP '^[a-d]' |
+---------------------+
|                   1 |
+---------------------+
~~~

Returns 1 if the string *`expr`* matches the regular expression specified by the pattern *`pat`*, 0 otherwise. If *`expr`* or *`pat`* is `NULL`, the return value is `NULL`.

如果正则匹配则返回1，否则返回0

在业务中的用法：

`r.buildVersion REGEXP CONCAT(l.version,'$')`

业务场景：需要匹配一个表中的字段是否在另一个表中出现且在最后

这里使用了concat进行了字段拼接，保证了正则和字段属性能形成一个大正则。

## 八、AndroidStudio下载问题

创建或build安卓项目时，有时会一直卡在某一个jar包的下载上，这时候可以通过配置阿里的源来解决，注意如果是7.0以下的gradle版本需要在build.gradle文件中配置：

> 注意配置maven仓库时如果是http的地址需要加上这句：allowInsecureProtocol = true

```
// Top-level build file where you can add configuration options common to all sub-projects/modules.
buildscript {
    repositories {
    maven {
            allowInsecureProtocol = true
            url 'http://maven.aliyun.com/nexus/content/groups/public'}
        google()
        mavenCentral()
    }
    dependencies {
        classpath "com.android.tools.build:gradle:4.1.1"
        classpath 'org.jetbrains.kotlin:kotlin-gradle-plugin:1.6.10'

        // NOTE: Do not place your application dependencies here; they belong
        // in the individual module build.gradle files
    }
}
allprojects {
    repositories {
        // maven { url 'https://maven.google.com' }
        maven {
            allowInsecureProtocol = true
            url 'http://maven.aliyun.com/nexus/content/groups/public'}
        jcenter()
        mavenCentral()
    }
}
task clean(type: Delete) {
    delete rootProject.buildDir
}
```

注意如果是7.0以上的gradle版本需要在settings.gradle文件中配置：

```
dependencyResolutionManagement {
    repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS)
    repositories {
        maven {
            allowInsecureProtocol = true
            url 'http://maven.aliyun.com/nexus/content/groups/public'}
        google()
        mavenCentral()
        jcenter() // Warning: this repository is going to shut down soon
    }
}
rootProject.name = "HelloWorld"
include ':app'
```

## 九、linux排查各文件夹的大小

遇到系统磁盘满了的情况可以使用以下命令逐一排查是哪个地方用量过大,其中--max-depth表示遍历深度或者说是目录层数，一般设置为1即可。

`du -h --max-depth=1`

## 十、SpringBoot手动管理事务

有时可能需要手动管理事务，方法如下：

```java
@Autowired
private PlatformTransactionManager platformTransactionManager;

@Autowired
private TransactionDefinition transactionDefinition;

public void test(){
    TransactionStatus transaction = platformTransactionManager.getTransaction(transactionDefinition);
    try{
        //......业务
        platformTransactionManager.commit(transaction);
    }catch (Exception e){
        platformTransactionManager.rollback(transaction);
    }
}
```

## 十一、MySQL的COLLATE导致不区分大小写

当我们搜索时发现MySQL对大小写不敏感，同时设置中也设置了严格区分大小写（0代表严格区分, 1代表不区分），如下图：

![image-20220804151905192](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/image-20220804151905192.png)

问题如下，有这么一条数据：

![image-20220804151714797](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/image-20220804151714797.png)

我们现在搜索它发现，这个数据不区分大小写

![image-20220804152002171](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/image-20220804152002171.png)

这个问题其实是因为MySQL的COLLATE（排序规则）造成的。COLLATE默认是与数据编码CHARSET相关的，一般来说每种CHARSET都指定一种COLLATE为默认值，比如Latin1编码的默认COLLATE为latin1_swedish_ci;比如utf8mb4的默认值为utf8mb4_general_ci。

很多COLLATE都带有ci字样，这是Case Insensitive的缩写，即大小写无关，也就是说”A”和”a”在排序和比较的时候是一视同仁的。select * from table1 where field1=”a”同样可以把field1为”A”的值选出来。与此同时，对于那些cs后缀的COLLATE，则是Case Sensitive，即大小写敏感的。

**collate规则**：

-  bin: 表示的是binary case sensitive collation，也就是说是区分大小写的
-  cs: case sensitive collation，区分大小写
-  ci: case insensitive collation，不区分大小写

> 我们可以用show collation查看mysql支持的所有COLLATE

因此回到此问题我们可以通过两种方式解决：

1. 可以将查询条件用binary()括起来。 比如上面sql语句改成这样`SELECT * FROM `user_info` where BINARY name = 'ZHANGSAN'` 

2. 将COLLATE修改为bin类型。比如`ALTER` `TABLE` `TABLENAME ``MODIFY` `COLUMN` `COLUMNNAME ``VARCHAR``(50) ``BINARY` `CHARACTER` `SET` `utf8 ``COLLATE` `utf8_bin ``DEFAULT` `NULL``;`

   又或者用navicat修改排序规则都可以

   ![image-20220804153010008](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/image-20220804153010008.png)

> 原理：
>
> 对于CHAR、VARCHAR和TEXT类型，BINARY属性可以为列分配该列字符集的 校对规则。BINARY属性是指定列字符集的二元 校对规则的简写。排序和比较基于数值字符值。因此也就自然区分了大小写。

## 十二、SpringBoot接口实现类切换

业务场景是这样的，不同的平台部署项目的接口实现需要不一样。比如A平台部署时需要我们的项目向OSS中上传文件，B平台部署时需要用MinIO作文件服务器，针对这种不同的情况我们可以使用`@ConditionalOnProperty`注解进行标注，其中value指的是配置文件中的key，havingValue表示配置文件中的值，如果配置文件中数据满足此值，那么就注入这个实现类。

举个例子，现在有个FileService接口，A客户要用OSS作服务器，B客户要用MinIO做服务器，我们就可以在实现类上进行标注：

```java
@ConditionalOnProperty(value = "file.type", havingValue = "oss")
@Service
public class FileServiceOssImpl implements FileService{}

@ConditionalOnProperty(value = "file.type", havingValue = "minio")
@Service
public class FileServiceMinIOImpl implements FileService{}
```

然后在配置文件中指定要注入哪个配置类：

~~~properties
#A客户
file.type=oss
#B客户
#file.type=minio
~~~

## 十三、jdbc时区切换

jdbc的URL中可以用serverTimezone指定时区，一般可以使用`serverTimezone=Asia/Shanghai`指定上海时间，如果向指定某一时区的时间可以用GMT标准时间指定，比如南非的时区在东二区所以其时区是：`serverTimezone=GMT%2B2`或北京在东八区其时区为：`serverTimezone=GMT%2B8`

## 十四、Nginx反向代理使用域名的缓存问题

~~~nginx
location /something {
            proxy_pass http://www.demo.com;	
        }
~~~

nginx反向代理使用域名时，nginx只会根据启动时从服务器获取的解析IP进行代理，直到下一次nginx重启，或者reload，因此当某个ip挂掉了之后可能就会一直访问不上，并报502等错误。解决方案就是重启nginx或reload nginx。

## 十五、唯一键索引和逻辑删除冲突的问题

逻辑删除和唯一性索引同时存在的情况下，已经逻辑删除的数据由于唯一性索引的约束无法再次添加。

这时可以将逻辑删除字段也加入唯一性索引就可以解决此问题。但是这样又多了新的问题就是再次添加同样的数据时无法进行删除。

此时可以通过将逻辑删除字段在删除时不设置为false或1等常规数据，而是通过主键id或当前时间戳代表被删除的数据，这样就可以完美解决此问题。

但是主键id或时间戳可能会很长，所以**可以通过置空的方式表示被删除的数据**，这种方式是目前来说最完美的解决方案了。*原理是在mysql 的innodb引擎中，是允许在唯一索引的字段中出现多个null值的。根据NULL的定义，NULL表示的是未知，因此两个NULL比较的结果既不相等，也不不等，结果仍然是未知。根据这个定义，多个NULL值的存在应该不违反唯一约束，所以是合理的，在oracel也是如此。*

> mybatisplus中更新时字段为null的话是不会更新的，因此可以用`@TableField(updateStrategy = FieldStrategy.IGNORED)`让该字段更新时忽略null，这样就可以将null插入到数据库了。

## 十六、Spring Cloud GateWay无法处理100 (Continue) Status

问题描述，给Gateway发送http的post请求时一直收不到响应。但是微服务端已经正确返回了。

通过网络抓包和问题定位最终发现问题出在了Gateway上。原因是客户端发送http请求后，请求头携带了一个100 (Continue) Status。这个状态可见[RFC文档](https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.2.3)

这个请求头主要的作用是它可以让客户端在发送请求数据之前去判断服务器是否愿意接收该数据，如果服务器愿意接收，客户端才会真正发送数据。这么做的原因是如果客户端直接发送请求数据，但是服务器又将该请求拒绝的话，这种行为将带来很大的资源开销。

> 这个状态码实际上是对如下场景的一种优化：客户端有一个较大的文件需要上传并保存，但是客户端不知道服务器是否愿意接受这个文件，所以希望在消耗网络资源进行传输之前，先询问一下服务器的意愿。实际操作为客户端发送一条特殊的请求报文，报文的头部应包含
>
> ```
> Expect: 100-continue
> ```
>
> 此时，如果服务器愿意接受，就会返回 100 Continue 状态码，反之则返回 417 Expectation Failed 状态码。对于客户端而言，如果客户端没有发送实际请求的打算，则不应该发送包含 100 Continue Expect 的报文，因为这样会让服务器误以为客户端将要发送一个请求。

为什么加上这个请求头gateway就无法返回了呢？因为并不是所有的HTTP应用都支持 100 Continue 这个状态码（例如HTTP/1.0及之前的版本的代理或服务器）。

> 实际上客户端不应该在发送 100 Continue Expect 后一直等待服务器的响应，在一定时间后，客户端应当直接发送计划发送的内容。而对于服务器而言，也不应当把 100 Continue 当作一个严格的判断方法。服务器有可能在发送回应之前就受到了客户端发来的主体报文。此时服务器就不需要再发送 100 Continue 作为回应了。但仍然需要在接受完成后返回适当的状态码。理论上，当服务器收到一个 100 Continue Expect 请求时，应当进行响应。但服务器永远也不应向没有发送 100 Continue Expect 请求的客户端发送100 Continue 状态码作为回应。这里提到的应当进行响应是指：假设服务器不打算接收客户端将要发送的主体报文，也应当做适当的响应（例如发送 417 Expectation Failed）而不是单纯的关闭连接，这样会对客户端在网络层面上产生影响。

这里可以自己进行尝试，加上这个请求头后，就会一直拿不到响应。

![image-20221212111618822](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/image-20221212111618822.png)

那么如何解决呢？那就是在SpringCloud GateWay中将头信息Expect去掉，或者我这里使用了nginx进行了转发，只要把这个头信息去掉就可以了。

下面给出我用wireshark抓包的图片：

第一次抓包，直连网关（下面地址是11888，网关端口号），post请求无响应值。

![image-20221212112053634](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/image-20221212112053634.png)

第二次抓包，走nginx（下面地址是8022，nginx转发网关端口号），post请求可以正常获得响应值

![image-20221212112302087](https://mypic-12138.oss-cn-beijing.aliyuncs.com/blog/picgo/image-20221212112302087.png)

## 十七、Mysql  FIND_IN_SET函数

FIND_IN_SET(str,strlist) ： str 要查询的字符串，strlist 需查询的字段，参数以`,`分隔，形式如 (1,2,6,8,10,22)；该函数的作用是查询字段(strlist)中是否包含(str)的结果，返回结果为null或记录。

示例：

~~~mysql
SELECT FIND_IN_SET('b', 'a,b,c,d');
// 结果：2
// 因为 b 在strlist集合中2的位置, a是位置1
 
select FIND_IN_SET('1', '1');
// 结果：1 
// 这时候的strlist集合有点特殊，只有一个字符串
 
select FIND_IN_SET('2', '1，2'); 
// 结果：2
 
select FIND_IN_SET('6', '1'); 
// 结果：0 strlist中不存在str，所以返回0。
~~~

主要业务场景：有一个表字段很多逗号的值（用逗号分开），然后查询时候传入一些值，匹配所有数据内包含查询传入的这些值的数据

## 十八、磁盘不足引起的net::ERR_INCOMPLETE_CHUNKED_ENCODING 200 (OK)

浏览器报错net::ERR_INCOMPLETE_CHUNKED_ENCODING 200 (OK)

可以从几方面进行排查：

- 丢包
- 响应数据被限制
- 读取流异常终止

常见的解决方法是修改nginx的配置文件，在对应的路径下(没有指明就location)里面增加

~~~nginx
proxy_buffer_size 1024k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小
proxy_buffers 16 1024k; #proxy_buffers缓冲区，网页平均在32k以下的设置
proxy_busy_buffers_size 2048k; #高负荷下缓冲大小（proxy_buffers*2）
proxy_temp_file_write_size 2048k;#设定缓存文件夹大小，大于这个值，将从upstream服务器传
~~~

这是因为nginx缓冲区不足导致的。但是我这里并不是因为缓冲区配置导致的，而是磁盘空间满了导致nginx缓冲区写失败导致的。最终通过清理磁盘空间解决了此问题。

## 十九、jar包项目启动卡死

`nohup java -jar`启动项目时，发现项目迟迟起不来，查看日志后发现项目一直卡死在连接数据库，最后通过注释掉`resolv.conf `文件中的`nameserver`，完成了项目的启动，这么做实际上是绕过了DNS解析步骤，从而避免了潜在的 DNS解析问题，使得Java 应用程序能够正常启动。然而，这并不是一种持久的解决方案，因为 DNS解析在很多应用中是必需的，例如涉及到域名解析、网络通信、API调用等。

后来通过取消刚刚在`resolv.conf `文件中对`nameserver`的注释，并在`nameserver`增加`114.114.114.114`（电信的DNS地址）发现，项目依旧可以正常启动。怀疑是云服务器的DNS解析不稳定导致的。

> 后续又等了一个多小时，将`resolv.conf `恢复成最开始的样子，发现项目也能正常启动了，所以推测此问题的最大的原因可能就是云服务器厂商的DNS解析不稳定导致的。

> resolv.conf是DNS客户机配置文件，用于设置DNS服务器的IP地址及DNS域名，还包括了主机的域名搜索顺序，该文件是由域名解析器(resolver，一个根据主机名解析IP地址的库)使用的配置文件，它的格式很简单，每行以一个关键字开头，后接一个或多个由空格隔开的参数，`resolv.conf`关键字分别是:
>
> - nameserver  定义DNS服务器的IP地址
> - domain     定义域名的搜索列表
> - sortlist      对返回的域名进行排序
>
> 最主要是nameserver关键字，如果没指定nameserver就找不到DNS服务器，

## 二十、gitlab 报错Forbidden

我这里的原因是因为同时拉取多个项目导致ip被封了，在Gitlab使用rack_attack做了并发访问的限制。

一般网上的解决方案是修改配置文件（`/etc/gitlab/gitlab.rb`）：

```
gitlab_rails['rack_attack_git_basic_auth'] = {
			 'enabled' => true,
			 'ip_whitelist' => ["127.0.0.1","Gitlab部署的IP地址"],
			 'maxretry' => 300,
			 'findtime' => 5,
			 'bantime' => 60
		 }
```

配置好后，执行`gitlab-ctl reconfigure`。

或者也可以通过删除redis的封的ip数据解决：

先使用`/opt/gitlab/embedded/bin/redis-cli -s /var/opt/gitlab/redis/redis.socket keys '*' | grep 'rack::attack'`查询被封的ip。

> 这里使用了`redis-cli -s` ，这是一个用于连接 Redis 服务器的命令，其中 `-s` 选项用于指定 Redis 服务器的套接字路径。通过指定套接字路径，可以连接到 Redis 服务器上非默认位置的套接字。

然后使用`/opt/gitlab/embedded/bin/redis-cli -s /var/opt/gitlab/redis/redis.socket keys '*' | grep 'rack::attack' | xargs /opt/gitlab/embedded/bin/redis-cli -s /var/opt/gitlab/redis/redis.socket DEL`删除被封的ip即可解决此问题。

## 二十一、Nginx 499错误日志

nginx源码对499状态码的定义如下：

~~~
 
/*
 * HTTP does not define the code for the case when a client closed
 * the connection while we are processing its request so we introduce
 * own code to log such situation when a client has closed the connection
 * before we even try to send the HTTP header to it
 */
 
#define NGX_HTTP_CLIENT_CLOSED_REQUEST 499
~~~

首先499 状态码不是 HTTP 的标准代码，
而是 Nginx 自己定义，用来记录服务端向客户端发送 HTTP 请求头之前，客户端已经关闭连接的一种情况。最常见的场景就是 timeout 设置不合理，Nginx 把请求转发上游服务器，上游服务器慢吞吞的处理，客户端等不及了主动断开链接，Nginx 就负责记录了 499。

我遇到的问题是因为不合理的客户端请求导致的大量499错误，由于该业务已经废弃，所以直接用nginx返回虚拟结果：

~~~nginx
location /api {
    default_type application/json;
    add_header Content-Type application/json;
    return 200 '{"message": "Hello, world!"}';
}
~~~

## 二十二、大文件大日志查找对应的内容

当想从大文件比如nginx日志中（几个G或者十几H）查找某个具体的内容，可以使用管道grep命令进行查找配合其他命令使用，比如tail

~~~sh
grep "pattern" largefile.txt | tail -n 1000
~~~

## 二十三、nginx封锁ip

在nginx中可以使用deny命令封锁ip，例子如下：

~~~nginx
location / {
    deny IP_ADDRESS;
    ...
}

~~~

或者可以使用 CIDR 表示法来指定一个 IP 范围。

~~~nginx
location / {
    deny 192.168.1.0/24;
    ...
}

~~~

## 二十四、手动触发JVM的GC

使用下面这个命令可以手动触发FULL GC

```
jmap -histo:live pid
```

> 参数解释：
>
> - `jmap`：Java Memory Map 工具，用于生成堆内存信息快照和分析 Java 堆内存的使用情况。
> - `-histo:live`：指定获取堆内存直方图（Histogram）时只包括活动对象，即不包括已被回收的对象。
> - `pid`：Java 进程的进程 ID，用于指定要分析的 Java 进程。
>
> 当你执行 `jmap -histo:live pid` 命令时，会在命令行中输出 Java 进程的堆内存信息直方图。直方图包含了不同类型对象的数量以及占用堆内存的大小，以便分析 Java 进程的内存使用情况。
>
> 执行 `jmap -histo:live pid` 命令会触发 Full GC（Full Garbage Collection）。Full GC 是指对整个 Java 堆（包括新生代和老年代）进行垃圾回收的过程，而不仅仅是针对新生代进行回收（Partial GC）。
>
> [原理](https://blog.csdn.net/lpw_cn/article/details/120701948)

## 二十五、lombok使用@Builder注解导致MybatisPlus结果集映射异常

> [原因原理参考连接](https://blog.csdn.net/tianmaxingkonger/article/details/128441369)

解决方式：

- 不用@Builder注解
- 加上@AllArgsConstructor，@NoArgsConstructor来声明构造器

## 二十六、跨域问题记录

问题背景：在部署测试服务时在78服务器上安装了nginx。并在80端口部署了vue项目。访问vue项目时，vue项目统一向后端发送的请求是发送到78服务器nginx监听的11888端口，然后将这个端口的所有请求反向代理到74服务器上，现在vue请求时浏览器报跨域错误。但是将请求URL单独拿出来放在浏览器里请求没有跨域报错。

> vue请求时报错信息是：Access to XMLHttpRequest at 'http://ServerIP:11888/oauth/login/captcha' from origin 'http://ServerIP' has been blocked by CORS policy: Response to preflight request doesn't pass access control check: No 'Access-Control-Allow-Origin' header is present on the requested resource.

先来了解一下跨域：

> 什么是跨域？
>
> 出于浏览器的同源策略限制。同源策略（Sameoriginpolicy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说Web是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。同源策略会阻止一个域的javascript脚本和另外一个域的内容进行交互。所谓同源（即指在同一个域）就是两个页面具有相同的协议（protocol），主机（host）和端口号（port）。
>
> 当一个请求url的协议、域名、端口三者之间任意一个与当前页面url不同即为跨域

再回看我的跨域报错，这里显示请求跨域。预检请求没有通过跨域。这里可以提出两个问题：

1. 为什么会发送预检请求？
2. 为什么会触发跨域？
3. 为什么将请求URL单独拿出来放在浏览器里请求没有跨域报错。

实际上第二个，第三个问题很好理解，虽然是在同一台服务器上，同一个协议，但是端口号不同所以会触发跨域检查。那么为什么单独拿出来放在浏览器里请求没有跨域报错？这是因为vue项目在80端口，而请求是请求11888端口，但是直接在浏览器请求没有这种两个端口的情况，所以不会跨域。

回头看第一个问题，为什么会发送预检请求？这里先区分一下简单请求和复杂请求

一次完整的请求不需要服务端预检，直接响应的，归为简单请求；而响应前需要预检的，称为预检请求，只有预检请求通过，才有接下来的简单请求。

> 什么时候会触发预检请求，当满足以下条件时：
>
> 若请求**满足所有下述条件**，则该请求可视为*简单请求*：
>
> - 使用下列方法之一：
>
>   - [`GET`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/GET)
>   - [`HEAD`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/HEAD)
>   - [`POST`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/POST)
>
> - 除了被用户代理自动设置的标头字段（例如`Connection`，`User-Agent`或其他在 Fetch 规范中定义为禁用标头名称的标头），允许人为设置的字段为 Fetch 规范定义的对 CORS 安全的标头字段集合。
>
>   。该集合为：
>
>   - [`Accept`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Accept)
>   - [`Accept-Language`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Accept-Language)
>   - [`Content-Language`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Language)
>   - [`Content-Type`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Type)（需要注意额外的限制）
>   - [`Range`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Range)（只允许[简单的范围标头值](https://fetch.spec.whatwg.org/#simple-range-header-value) 如 `bytes=256-` 或 `bytes=127-255`）
>
> - `Content-Type`标头所指定的媒体类型的值仅限于下列三者之一：
>
>   - `text/plain`
>   - `multipart/form-data`
>   - `application/x-www-form-urlencoded`
>
> - 如果请求是使用 [`XMLHttpRequest`](https://developer.mozilla.org/zh-CN/docs/Web/API/XMLHttpRequest) 对象发出的，在返回的 [`XMLHttpRequest.upload`](https://developer.mozilla.org/zh-CN/docs/Web/API/XMLHttpRequest/upload) 对象属性上没有注册任何事件监听器；也就是说，给定一个 [`XMLHttpRequest`](https://developer.mozilla.org/zh-CN/docs/Web/API/XMLHttpRequest) 实例 `xhr`，没有调用 `xhr.upload.addEventListener()`，以监听该上传请求。
>
> - 请求中没有使用 [`ReadableStream`](https://developer.mozilla.org/zh-CN/docs/Web/API/ReadableStream) 对象。
>
> 原文如下：
>
> [关于CORS的开发文档](https://developer.mozilla.org/zh-CN/docs/web/http/cors)

实际上我这里是因为content-type是application/json以及使用了自定义请求头导致的。

跨域了我们就要解决，这时我们可以在nginx中根据报错提示，加上`Access-Control-Allow-Origin`的配置。nginx的配置如下：

```nginx
add_header 'Access-Control-Allow-Origin' '*';
        	add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
        	add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';
if ($request_method = 'OPTIONS') {
    add_header 'Access-Control-Allow-Origin' '*';
    add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
    add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';
    add_header 'Access-Control-Max-Age' 1728000;
    add_header 'Content-Type' 'text/plain; charset=utf-8';
    add_header 'Content-Length' 0;
    return 204;
}
```

到这里基本就能解决，但是我这里又报了一个错误：

> Access to XMLHttpRequest at 'http://ServerIP:11888/oauth/v1/oauth/login/captcha' from origin 'http:/ServerIP' has been blocked by CORS policy: Request header field satoken is not allowed by Access-Control-Allow-Headers in preflight response.

这里是因为我使用了自定义请求头导致的，这时就需要在Access-Control-Allow-Headers中加上允许的请求头，即：

```nginx
add_header  'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization,satoken';
```

> 附注：
>
> 关于Access-Control-Max-Age
> Access-Control-Max-Age不是针对请求域名有效的，是请求的完成路径有效的，比如第一次发出。
>
> `www.exanple.com/api/corsGet`会产生一次options请求和一次post请求，然后我再请求一次，这时没有预检请求了，只有post请求。但再发送一次`www.exanple.com/api/corsSave`请求，会发现又产生了一次options请求和一次post请求，所以Access-Control-Max-Age不是针对相同的origin有效，而是针对相同的requestUrl有效。
>
> 其实更严格来讲，是针对请求头和请求方法，比对是否一致，来决定是否需要重新发起预检；另外，如果调试模式勾选了disable-cache，也会导致每次都会预检，导致Access-Control-Max-Age设置无效；

> PPS：
>
> 关于CORS具体的知识可见：
>
> [关于CORS的开发文档](https://developer.mozilla.org/zh-CN/docs/web/http/cors)

## 二十七、Docker启动失败的问题

问题背景：服务器重启后导致docker无法启动，输入`docker ps`显示：

```
Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
```

输入`systemctl status docker.service`,显示一下报错：

```
root@ecs-xxxx:/# systemctl status docker.service
● docker.service - Docker Application Container Engine
   Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)
   Active: failed (Result: exit-code) since Tue 2023-10-31 08:47:57 CST; 10s ago
     Docs: https://docs.docker.com
  Process: 2106 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock (code=exited, status=205/LIMITS)
 Main PID: 2106 (code=exited, status=205/LIMITS)

Oct 31 08:47:57 ecs-d5b1 systemd[1]: docker.service: Service hold-off time over, scheduling restart.
Oct 31 08:47:57 ecs-d5b1 systemd[1]: docker.service: Scheduled restart job, restart counter is at 3.
Oct 31 08:47:57 ecs-d5b1 systemd[1]: Stopped Docker Application Container Engine.
Oct 31 08:48:00 ecs-d5b1 systemd[1]: docker.service: Start request repeated too quickly.
Oct 31 08:48:00 ecs-d5b1 systemd[1]: docker.service: Failed with result 'exit-code'.
Oct 31 08:48:00 ecs-d5b1 systemd[1]: Failed to start Docker Application Container Engine.
```

并且docker也无法启动`systemctl start docker`：

```
root@ecs-d5b1:/# sudo systemctl start docker

Job for docker.service failed because the control process exited with error code.
See "systemctl status docker.service" and "journalctl -xe" for details.
```

通过`journalctl -xe`查看报错日志显示：

```
Oct 31 08:48:31 ecs-d5b1 systemd[1]: containerd.service: Scheduled restart job, restart counter is at 8876.
-- Subject: Automatic restarting of a unit has been scheduled
-- Defined-By: systemd
-- Support: http://www.ubuntu.com/support
-- 
-- Automatic restarting of the unit containerd.service has been scheduled, as the result for
-- the configured Restart= setting for the unit.
Oct 31 08:48:31 ecs-d5b1 systemd[1]: Stopped containerd container runtime.
-- Subject: Unit containerd.service has finished shutting down
-- Defined-By: systemd
-- Support: http://www.ubuntu.com/support
-- 
-- Unit containerd.service has finished shutting down.
Oct 31 08:48:31 ecs-d5b1 systemd[1]: Starting containerd container runtime...
-- Subject: Unit containerd.service has begun start-up
-- Defined-By: systemd
-- Support: http://www.ubuntu.com/support
-- 
-- Unit containerd.service has begun starting up.
Oct 31 08:48:31 ecs-d5b1 systemd[2207]: containerd.service: Failed to adjust resource limit LimitNOFILE: Operation not permitted
Oct 31 08:48:31 ecs-d5b1 systemd[2207]: containerd.service: Failed at step LIMITS spawning /sbin/modprobe: Operation not permitted
-- Subject: Process /sbin/modprobe could not be executed
-- Defined-By: systemd
-- Support: http://www.ubuntu.com/support
-- 
-- The process /sbin/modprobe could not be executed and failed.
-- 
-- The error number returned by this process is 1.
Oct 31 08:48:31 ecs-d5b1 systemd[2208]: containerd.service: Failed to adjust resource limit LimitNOFILE: Operation not permitted
Oct 31 08:48:31 ecs-d5b1 systemd[2208]: containerd.service: Failed at step LIMITS spawning /usr/bin/containerd: Operation not permitted
-- Subject: Process /usr/bin/containerd could not be executed
-- Defined-By: systemd
-- Support: http://www.ubuntu.com/support
-- 
-- The process /usr/bin/containerd could not be executed and failed.
-- 
-- The error number returned by this process is 1.
Oct 31 08:48:31 ecs-d5b1 systemd[1]: containerd.service: Main process exited, code=exited, status=205/LIMITS
Oct 31 08:48:31 ecs-d5b1 systemd[1]: containerd.service: Failed with result 'exit-code'.
Oct 31 08:48:31 ecs-d5b1 systemd[1]: Failed to start containerd container runtime.
-- Subject: Unit containerd.service has failed
-- Defined-By: systemd
-- Support: http://www.ubuntu.com/support
-- 
-- Unit containerd.service has failed.
-- 
-- The result is RESULT.
```

怀疑是containerd在服务器重启后存在问题，于是根据报错指引尝试修改了containerd的`LimitNOFILE`，操作步骤如下：

1. 修改`/lib/systemd/system/containerd.service`文件，将其中的`LimitNOFILE`修改为65535

2. 执行以下命令重启

   ```sh
   sudo systemctl daemon-reload
   sudo systemctl restart containerd
   ```

3. 重启docker

经过此步骤，docker恢复启动，此问题解决。

**总结：目前具体的产生此问题的原因暂未排查到，通过修改上述配置可以临时解决此问题。**
